{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_hi(name):\n",
    "    print(f'{name}')\n",
    "\n",
    "def moneycontrol(mc_url):\n",
    "    mc_data = urlopen(mc_url)\n",
    "    mc_html = mc_data.read()\n",
    "\n",
    "    # Parsing the Data\n",
    "    mc_soup = soup(mc_html, 'html.parser')\n",
    "\n",
    "    # Start Extracting the data\n",
    "    headers = mc_soup.findAll('th')\n",
    "\n",
    "    column_titles = [ct.text for ct in headers]\n",
    "    column_titles = column_titles[:6]\n",
    "    # column_titles[6] = column_titles[6][0:17]\n",
    "    ## Upto Done with Headers\n",
    "\n",
    "    # List out the all company name\n",
    "    span = mc_soup.find_all('span', class_='gld13')\n",
    "    company_span_list = [spani.text[:-37] for spani in span]\n",
    "\n",
    "    filename = 'mc_NIFTY_500_company.csv'\n",
    "    with open(filename, 'w', encoding='utf-8', newline='') as f:\n",
    "        company_name = '\\n'.join(company_span_list)\n",
    "        f.write(company_name)\n",
    "        f.close()\n",
    "    ## Upto Company_name list Done here\n",
    "    ## Now It's time for Valuable Digits\n",
    "    # First of all we extract the elements which is not neccessory for final data\n",
    "\n",
    "    ##### Removing the tags\n",
    "    # Remove p elements\n",
    "    tdrs = mc_soup.find_all('p')\n",
    "    for re in tdrs:\n",
    "        re.decompose()\n",
    "    # Remove strongs elements\n",
    "    tdrst = mc_soup.find_all('strong')\n",
    "    for re in tdrs:\n",
    "        re.decompose()\n",
    "    tws = mc_soup.find_all('div', {'class': 'title2'})\n",
    "    for re in tws:\n",
    "        re.decompose()\n",
    "    tws = mc_soup.find_all('td', {'class': 'vol'})\n",
    "    for re in tws:\n",
    "        re.decompose()\n",
    "    tws = mc_soup.find_all('td', {'class': 'del'})\n",
    "    for re in tws:\n",
    "        re.decompose()\n",
    "    twsas = mc_soup.find_all('td', {'width': '300'})\n",
    "    for re in twsas:\n",
    "        re.decompose()\n",
    "\n",
    "    # final Digits\n",
    "    ## td_data is Our final Valuable Data\n",
    "    td_data = mc_soup.find_all('td', {'align': 'right'})\n",
    "\n",
    "    # Final digit List\n",
    "    ## Little bit of data cleansing :)\n",
    "    digit_list = []\n",
    "    for tt in td_data[0:2505]:\n",
    "        x = tt.text\n",
    "        x = x.replace(\",\", \"\")\n",
    "        digit_list.append(x)\n",
    "\n",
    "    ############################## Done with This\n",
    "\n",
    "    # data setup in CSV\n",
    "    with open('mc_NIFTY_digits.csv', 'w', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        #      writer.writerow(column_titles[1:])\n",
    "        for i in range(0, 2505, 5):\n",
    "            writer.writerow([digit_list[i], digit_list[i + 1], digit_list[i + 2], digit_list[i + 3], digit_list[i + 4]])\n",
    "        f.close()\n",
    "    ############33 All done with CSV Table partition\n",
    "\n",
    "    # Clear entire csv file\n",
    "    with open('final_mc_NIFTY_list.csv', 'w+', encoding='utf-8') as f:\n",
    "        f.truncate()\n",
    "        f.close\n",
    "\n",
    "    with open('mc_NIFTY_digits.csv', 'r', encoding='utf-8') as read_temp, open('mc_NIFTY_500_company.csv', 'r',encoding='utf-8') as header, open(\n",
    "            'final_mc_NIFTY_list.csv', 'a', encoding='utf-8', newline='') as final_list:\n",
    "        reader = csv.reader(read_temp)\n",
    "        writer = csv.reader(header)\n",
    "        final_obj = csv.writer(final_list)\n",
    "\n",
    "        final_obj.writerow(column_titles)  # Put Headings on top of list\n",
    "        for a, b in zip(writer, reader):\n",
    "            final_obj.writerow(a + b)  # write 50 rows (Company_name+ value)\n",
    "        read_temp.close()\n",
    "        header.close()\n",
    "        final_list.close()\n",
    "\n",
    "        ## Generate Excel file\n",
    "        csv_list = pd.read_csv('final_mc_NIFTY_list.csv')\n",
    "\n",
    "        NIFTY_500_sheet = pd.ExcelWriter('NIFTY_500_sheet.xlsx')\n",
    "        csv_list.to_excel(NIFTY_500_sheet, index=False)\n",
    "        NIFTY_500_sheet.save()\n",
    "\n",
    "        ### Now remove the unnnecessory CSV files\n",
    "        os.remove('mc_NIFTY_500_company.csv')\n",
    "        os.remove('mc_NIFTY_digits.csv')\n",
    "        print('SpreadSheet is Ready for U!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moneycontrol\n",
      "SpreadSheet is Ready for U!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print_hi('Moneycontrol')\n",
    "    \n",
    "    mc_url = \"https://www.moneycontrol.com/stocks/marketstats/nse-mostactive-stocks/nifty-500-7/\"\n",
    "    moneycontrol(mc_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
